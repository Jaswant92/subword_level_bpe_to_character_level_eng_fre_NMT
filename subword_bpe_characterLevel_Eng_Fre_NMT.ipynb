{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TaFWKDUwej1c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from string import digits\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import re\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model\n",
    "#from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
    "#from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1066,
     "status": "ok",
     "timestamp": 1562230485180,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "fb900Xy7ej1w",
    "outputId": "e1dde68f-8c87-44a3-b656-40c1972ac098"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead, passing sep='\\t'.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "lines= pd.read_table('mar1.txt', names=['eng', 'fre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4618,
     "status": "ok",
     "timestamp": 1562230494074,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "s7wYHWFne92G",
    "outputId": "628224f4-5b52-4d47-bda8-a795c49aa8ec"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bpemb in /usr/local/lib/python3.6/dist-packages (0.3.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from bpemb) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bpemb) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bpemb) (1.16.4)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from bpemb) (0.1.82)\n",
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (from bpemb) (3.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->bpemb) (1.24.3)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.8.4)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim->bpemb) (1.3.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim->bpemb) (1.9.175)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.175 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (1.12.175)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim->bpemb) (0.9.4)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.175->boto3->smart-open>=1.2.1->gensim->bpemb) (2.5.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.175->boto3->smart-open>=1.2.1->gensim->bpemb) (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install bpemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "80sPwkApej16"
   },
   "outputs": [],
   "source": [
    "from bpemb import BPEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 973,
     "status": "ok",
     "timestamp": 1562218543850,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "QhPfpbaxej2C",
    "outputId": "f7a2b006-3be4-4774-8c14-41263c3ae985"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               Va !\n",
       "1                            Cours !\n",
       "2                           Courez !\n",
       "3                         Ça alors !\n",
       "4                           Au feu !\n",
       "5                         À l'aide !\n",
       "6                             Saute.\n",
       "7                        Ça suffit !\n",
       "8                             Stop !\n",
       "9                       Arrête-toi !\n",
       "10                         Attends !\n",
       "11                        Attendez !\n",
       "12                     Je comprends.\n",
       "13                         J'essaye.\n",
       "14                      J'ai gagné !\n",
       "15                 Je l'ai emporté !\n",
       "16                          Oh non !\n",
       "17                         Attaque !\n",
       "18                        Attaquez !\n",
       "19                           Santé !\n",
       "20                   À votre santé !\n",
       "21                           Merci !\n",
       "22                         Lève-toi.\n",
       "23                       J'ai pigé !\n",
       "24                         Compris !\n",
       "25                            Pigé ?\n",
       "26                         Compris ?\n",
       "27                      T'as capté ?\n",
       "28                            Monte.\n",
       "29                           Montez.\n",
       "                    ...             \n",
       "1970                 J'en déciderai.\n",
       "1971                Je le déciderai.\n",
       "1972           J'arriverai à entrer.\n",
       "1973      Je vais aller le chercher.\n",
       "1974             J'irai le chercher.\n",
       "1975                  Je me lèverai.\n",
       "1976            J'y vais maintenant.\n",
       "1977                    J'irai voir.\n",
       "1978               Je m'en sortirai.\n",
       "1979                     Je crierai.\n",
       "1980                 Je l'essayerai.\n",
       "1981                 Je le tenterai.\n",
       "1982    J'ai également dix-sept ans.\n",
       "1983             Je suis Finlandais.\n",
       "1984            Je suis Finlandaise.\n",
       "1985                Je suis italien.\n",
       "1986              Je suis boulanger.\n",
       "1987             Je suis boulangère.\n",
       "1988       Je suis tout à fait prêt.\n",
       "1989      Je suis tout à fait prête.\n",
       "1990                     J'ai honte.\n",
       "1991            Je suis à la maison.\n",
       "1992         Je suis dans la maison.\n",
       "1993               Je suis perplexe.\n",
       "1994                   Je suis béni.\n",
       "1995                  Je suis bénie.\n",
       "1996                Je suis prudent.\n",
       "1997               Je suis prudente.\n",
       "1998                    Je suis sûr.\n",
       "1999                Je suis certain.\n",
       "Name: fre, Length: 2000, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.fre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "eOXWcM4xej2N",
    "outputId": "d9418d2d-38ea-4b23-826c-00f27c3a21a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 171,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lines.eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1562230502453,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "SNKXe0_Hej2W",
    "outputId": "55f9c979-fd54-433a-99f9-d19f3c0030f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "bpemb_en = BPEmb(lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "colab_type": "code",
    "id": "_UBNbdMtej2e",
    "outputId": "71895c84-7755-477c-e87e-cd66181a83ce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "bpemb_fr = BPEmb(lang=\"fr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lowercase all characters\n",
    "lines.eng=lines.eng.apply(lambda x: x.lower())\n",
    "lines.fre=lines.fre.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove quotes\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\"'\", '', x))\n",
    "lines.fre=lines.fre.apply(lambda x: re.sub(\"'\", '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude = set(string.punctuation) # Set of all special characters\n",
    "# Remove all the special characters\n",
    "lines.eng=lines.eng.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))\n",
    "lines.fre=lines.fre.apply(lambda x: ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all numbers from text\n",
    "remove_digits = str.maketrans('', '', digits)\n",
    "lines.eng=lines.eng.apply(lambda x: x.translate(remove_digits))\n",
    "lines.fre = lines.fre.apply(lambda x: re.sub(\"[0123456789]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove extra spaces\n",
    "lines.eng=lines.eng.apply(lambda x: x.strip())\n",
    "lines.fre=lines.fre.apply(lambda x: x.strip())\n",
    "print(lines.eng)\n",
    "lines.eng=lines.eng.apply(lambda x: re.sub(\" +\", \" \", x))\n",
    "lines.fre=lines.fre.apply(lambda x: re.sub(\" +\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add $ and # tokens to target sequences\n",
    "lines.fre = lines.fre.apply(lambda x : '$_ '+ x + ' _#')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOING THE BYTE PER ENCODING OF SOURCE SIDE SENTENCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IheduqzBej2v"
   },
   "outputs": [],
   "source": [
    "subword_eng=bpemb_en.encode(lines.eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pMyx5CbSej3M"
   },
   "outputs": [],
   "source": [
    "#Making the Pickle File of subword\n",
    "pickle.dump(subword_eng,open(\"sub_only_eng.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZEhH82ZewaG"
   },
   "outputs": [],
   "source": [
    "all_sub_eng_vocab=pickle.load(open(\"all_sub_eng_vocab.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCTQNh7lfH3w"
   },
   "outputs": [],
   "source": [
    "sub_only_eng=pickle.load(open(\"sub_only_eng.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 794,
     "status": "ok",
     "timestamp": 1561970820763,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "At_A_2GPfU8L",
    "outputId": "72630dc9-fc78-4de8-bef9-d3912aa8b6e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sub_only_eng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01L17CNFej3o"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e14exjI5ej3w"
   },
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "C7J_5_89ej31",
    "outputId": "41365140-8360-4514-c455-05ffc08f285b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 59,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbNVXHYjej3-"
   },
   "source": [
    "## For converting list to series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Gx_zX3V7ej3_"
   },
   "outputs": [],
   "source": [
    "sub_only_eng=pd.Series(sub_only_eng) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "cANtlhVpej5_",
    "outputId": "e874b023-253e-4a4a-f525-1ad8fc66737f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 2)"
      ]
     },
     "execution_count": 138,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9oy_0v2bbgm"
   },
   "outputs": [],
   "source": [
    "##LOADING PICKLE FILE OF THE VOCABULARY OF SUBWORD OF ENG AND SUBWORD ENG AND SUBWORD FRENCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bt937ZDib2-x"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wg10sR7Sb5lB"
   },
   "outputs": [],
   "source": [
    "sub_only_eng=pickle.load(open(\"sub_only_eng.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1u9Zdcl3cYgR"
   },
   "outputs": [],
   "source": [
    "all_sub_eng_vocab=pickle.load(open(\"all_sub_eng_vocab.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1216,
     "status": "ok",
     "timestamp": 1562230580100,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "xhVITuk9ej66",
    "outputId": "7dcb6f74-08ce-425e-817f-b5dc2bf90317"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29880 total characters and 43 unique characters in your data.\n",
      "['m', 'â', 'o', 'q', 'i', 'ï', 'k', 'f', 's', '«', 'ç', 't', 'c', '\\u202f', 'n', 'é', 'ê', 'e', 'x', 'p', '\\n', 'z', 'b', 'v', 'a', 'î', 'ô', 'd', 'r', 'à', 'j', 'œ', 'u', '’', 'è', 'g', 'ù', 'û', ' ', 'y', '»', 'l', 'h']\n"
     ]
    }
   ],
   "source": [
    "#LOADING FRENCH FILE AND MAKING THE VOCAB OF FRENCH CHARACTERS\n",
    "data = open('fre.txt', 'r').read()\n",
    "chars = list(set(data))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('There are %d total characters and %d unique characters in your data.' % (data_size, vocab_size))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 937,
     "status": "ok",
     "timestamp": 1562230586001,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "gS-_xB2hi4lY",
    "outputId": "98e258ec-9a46-4105-e071-8db264f4a7f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "#To get maximum number of the character in a line of the french sentence\n",
    "file = open('fre.txt', 'r').readlines()\n",
    "print(len(file))\n",
    "length = [len(x) for x in file]\n",
    "print(max(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dhI9iMjRMwUK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 943,
     "status": "ok",
     "timestamp": 1562230600673,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "e9Gda8HjhjMF",
    "outputId": "8e0586c0-f2af-472b-f66a-a1c0d84b59a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '\\n', 1: ' ', 2: 'a', 3: 'b', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'j', 12: 'k', 13: 'l', 14: 'm', 15: 'n', 16: 'o', 17: 'p', 18: 'q', 19: 'r', 20: 's', 21: 't', 22: 'u', 23: 'v', 24: 'x', 25: 'y', 26: 'z', 27: '«', 28: '»', 29: 'à', 30: 'â', 31: 'ç', 32: 'è', 33: 'é', 34: 'ê', 35: 'î', 36: 'ï', 37: 'ô', 38: 'ù', 39: 'û', 40: 'œ', 41: '’', 42: '\\u202f'}\n",
      "{'\\n': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'x': 24, 'y': 25, 'z': 26, '«': 27, '»': 28, 'à': 29, 'â': 30, 'ç': 31, 'è': 32, 'é': 33, 'ê': 34, 'î': 35, 'ï': 36, 'ô': 37, 'ù': 38, 'û': 39, 'œ': 40, '’': 41, '\\u202f': 42}\n"
     ]
    }
   ],
   "source": [
    "#MAKING THE DICTIONARY OF CHARCTER LIST OF FRENCH\n",
    "char_to_ix = { ch:i for i,ch in enumerate(sorted(chars)) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(sorted(chars)) }\n",
    "print(ix_to_char)\n",
    "print(char_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADDING SUM CHARCTERS TO THE DICTIONARY WHICH WAS NOT PRESENT\n",
    "char_to_ix['$']=44\n",
    "char_to_ix['#']=45\n",
    "char_to_ix['_']=46\n",
    "ix_to_char[44]='$'\n",
    "ix_to_char[45]='#'\n",
    "ix_to_char[46]='_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OcoXxds8ej7b"
   },
   "outputs": [],
   "source": [
    "# Vocabulary of English sub_words\n",
    "all_eng_sub_words=set()\n",
    "for eng in subword_eng:\n",
    "    print(eng)\n",
    "    for word in eng:\n",
    "        print(word)\n",
    "        if word not in all_eng_sub_words:\n",
    "            all_eng_sub_words.add(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JsaoURRZej7d"
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wfmp5ODnej72"
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1562230684970,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "BhrnbEpLej77",
    "outputId": "acc2ee42-b151-4d35-e6cf-920c535d644d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 130,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Max Length of source sequence\n",
    "lenght_list=[]\n",
    "for eng in sub_only_eng:\n",
    "    #print(eng)\n",
    "    lenght_list.append(len(eng))\n",
    "    #print(lenght_list)\n",
    "max_length_src = np.max(lenght_list)\n",
    "\n",
    "max_length_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the max length same on both encoder and Decoder Side\n",
    "max_length_src=39\n",
    "max_length_tar=39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 914,
     "status": "ok",
     "timestamp": 1562230726415,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "-iJj2fHoej8t",
    "outputId": "82998f8a-a497-4ed4-d237-c47e30b30915"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713, 43)"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_words = sorted(list(all_sub_eng_vocab))\n",
    "target_words = sorted(list(chars))\n",
    "num_encoder_tokens = len(all_sub_eng_vocab)\n",
    "num_decoder_tokens = len(chars)\n",
    "num_encoder_tokens, num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1562219146944,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "z5ZvQkQuMISc",
    "outputId": "e3de8bfe-fa65-4c1e-9956-761ad2b1898a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1186,
     "status": "ok",
     "timestamp": 1562230732187,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "ZhFMXgDZej8x",
    "outputId": "577a7dfe-c608-4de1-ea5c-2a3debb2900d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_decoder_tokens += 4 # For zero padding\n",
    "num_decoder_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FntT_QGHej80"
   },
   "outputs": [],
   "source": [
    "input_token_index = dict([(word, i+1) for i, word in enumerate(input_words)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "or8E7hFRej87"
   },
   "outputs": [],
   "source": [
    "target_token_index = dict([(word, i+1) for i, word in enumerate(target_words)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1297,
     "status": "ok",
     "timestamp": 1562134501190,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "eD1dav7Vej88",
    "outputId": "23648280-3381-4df1-dc12-35a8225fea27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['\\n', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '«', '»', 'à', 'â', 'ç', 'è', 'é', 'ê', 'î', 'ï', 'ô', 'ù', 'û', 'œ', '’', '\\u202f'])"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict((i, word) for word, i in input_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 719,
     "status": "ok",
     "timestamp": 1562230751942,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "0d5v8kEUej9D",
    "outputId": "53e7fd75-386a-412c-93c7-5a9884a7b8e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'ab',\n",
       " 3: 'ad',\n",
       " 4: 'aded',\n",
       " 5: 'af',\n",
       " 6: 'aff',\n",
       " 7: 'ag',\n",
       " 8: 'ailed',\n",
       " 9: 'ak',\n",
       " 10: 'ake',\n",
       " 11: 'aken',\n",
       " 12: 'aking',\n",
       " 13: 'am',\n",
       " 14: 'ama',\n",
       " 15: 'amed',\n",
       " 16: 'ap',\n",
       " 17: 'ar',\n",
       " 18: 'ard',\n",
       " 19: 'ase',\n",
       " 20: 'astic',\n",
       " 21: 'asty',\n",
       " 22: 'at',\n",
       " 23: 'ate',\n",
       " 24: 'ated',\n",
       " 25: 'ating',\n",
       " 26: 'ats',\n",
       " 27: 'ax',\n",
       " 28: 'ay',\n",
       " 29: 'az',\n",
       " 30: 'b',\n",
       " 31: 'ber',\n",
       " 32: 'ble',\n",
       " 33: 'body',\n",
       " 34: 'by',\n",
       " 35: 'cel',\n",
       " 36: 'ct',\n",
       " 37: 'd',\n",
       " 38: 'ded',\n",
       " 39: 'ding',\n",
       " 40: 'e',\n",
       " 41: 'ed',\n",
       " 42: 'edy',\n",
       " 43: 'ell',\n",
       " 44: 'elled',\n",
       " 45: 'ely',\n",
       " 46: 'en',\n",
       " 47: 'ep',\n",
       " 48: 'er',\n",
       " 49: 'ers',\n",
       " 50: 'es',\n",
       " 51: 'ess',\n",
       " 52: 'essed',\n",
       " 53: 'est',\n",
       " 54: 'et',\n",
       " 55: 'ets',\n",
       " 56: 'ey',\n",
       " 57: 'fer',\n",
       " 58: 'fic',\n",
       " 59: 'ful',\n",
       " 60: 'get',\n",
       " 61: 'h',\n",
       " 62: 'hed',\n",
       " 63: 'i',\n",
       " 64: 'ible',\n",
       " 65: 'ice',\n",
       " 66: 'iced',\n",
       " 67: 'ick',\n",
       " 68: 'id',\n",
       " 69: 'ide',\n",
       " 70: 'iding',\n",
       " 71: 'ied',\n",
       " 72: 'ies',\n",
       " 73: 'iful',\n",
       " 74: 'iled',\n",
       " 75: 'in',\n",
       " 76: 'ined',\n",
       " 77: 'ing',\n",
       " 78: 'ink',\n",
       " 79: 'inn',\n",
       " 80: 'inted',\n",
       " 81: 'iot',\n",
       " 82: 'ious',\n",
       " 83: 'ip',\n",
       " 84: 'ird',\n",
       " 85: 'ired',\n",
       " 86: 'ise',\n",
       " 87: 'ised',\n",
       " 88: 'it',\n",
       " 89: 'ited',\n",
       " 90: 'its',\n",
       " 91: 'ive',\n",
       " 92: 'ives',\n",
       " 93: 'iz',\n",
       " 94: 'ize',\n",
       " 95: 'k',\n",
       " 96: 'ked',\n",
       " 97: 'ks',\n",
       " 98: 'ky',\n",
       " 99: 'le',\n",
       " 100: 'led',\n",
       " 101: 'less',\n",
       " 102: 'll',\n",
       " 103: 'lo',\n",
       " 104: 'ly',\n",
       " 105: 'm',\n",
       " 106: 'ms',\n",
       " 107: 'n',\n",
       " 108: 'ne',\n",
       " 109: 'ny',\n",
       " 110: 'o',\n",
       " 111: 'ob',\n",
       " 112: 'od',\n",
       " 113: 'oke',\n",
       " 114: 'oking',\n",
       " 115: 'oll',\n",
       " 116: 'olog',\n",
       " 117: 'ome',\n",
       " 118: 'oms',\n",
       " 119: 'on',\n",
       " 120: 'oned',\n",
       " 121: 'ony',\n",
       " 122: 'op',\n",
       " 123: 'or',\n",
       " 124: 'ore',\n",
       " 125: 'ored',\n",
       " 126: 'ores',\n",
       " 127: 'os',\n",
       " 128: 'osen',\n",
       " 129: 'ot',\n",
       " 130: 'other',\n",
       " 131: 'ours',\n",
       " 132: 'out',\n",
       " 133: 'ow',\n",
       " 134: 'ows',\n",
       " 135: 'p',\n",
       " 136: 'ped',\n",
       " 137: 'pose',\n",
       " 138: 'pr',\n",
       " 139: 're',\n",
       " 140: 'ream',\n",
       " 141: 'ree',\n",
       " 142: 'res',\n",
       " 143: 'rew',\n",
       " 144: 'ri',\n",
       " 145: 'ried',\n",
       " 146: 'ry',\n",
       " 147: 'rying',\n",
       " 148: 's',\n",
       " 149: 'self',\n",
       " 150: 'set',\n",
       " 151: 't',\n",
       " 152: 'ted',\n",
       " 153: 'ts',\n",
       " 154: 'ual',\n",
       " 155: 'ub',\n",
       " 156: 'uck',\n",
       " 157: 'ucky',\n",
       " 158: 'ue',\n",
       " 159: 'uff',\n",
       " 160: 'ugh',\n",
       " 161: 'umb',\n",
       " 162: 'ume',\n",
       " 163: 'une',\n",
       " 164: 'unk',\n",
       " 165: 'up',\n",
       " 166: 'ured',\n",
       " 167: 'us',\n",
       " 168: 'use',\n",
       " 169: 'uss',\n",
       " 170: 'ute',\n",
       " 171: 'uts',\n",
       " 172: 'v',\n",
       " 173: 've',\n",
       " 174: 'wn',\n",
       " 175: 'y',\n",
       " 176: 'ying',\n",
       " 177: 'ys',\n",
       " 178: 'zy',\n",
       " 179: '▁',\n",
       " 180: '▁a',\n",
       " 181: '▁aboard',\n",
       " 182: '▁above',\n",
       " 183: '▁accept',\n",
       " 184: '▁after',\n",
       " 185: '▁again',\n",
       " 186: '▁age',\n",
       " 187: '▁agre',\n",
       " 188: '▁agree',\n",
       " 189: '▁agreed',\n",
       " 190: '▁ahead',\n",
       " 191: '▁aim',\n",
       " 192: '▁air',\n",
       " 193: '▁all',\n",
       " 194: '▁alone',\n",
       " 195: '▁along',\n",
       " 196: '▁also',\n",
       " 197: '▁am',\n",
       " 198: '▁answer',\n",
       " 199: '▁any',\n",
       " 200: '▁anyone',\n",
       " 201: '▁ap',\n",
       " 202: '▁are',\n",
       " 203: '▁armed',\n",
       " 204: '▁around',\n",
       " 205: '▁art',\n",
       " 206: '▁as',\n",
       " 207: '▁ash',\n",
       " 208: '▁aside',\n",
       " 209: '▁ask',\n",
       " 210: '▁asked',\n",
       " 211: '▁ass',\n",
       " 212: '▁at',\n",
       " 213: '▁attack',\n",
       " 214: '▁attend',\n",
       " 215: '▁aw',\n",
       " 216: '▁away',\n",
       " 217: '▁b',\n",
       " 218: '▁back',\n",
       " 219: '▁bad',\n",
       " 220: '▁baker',\n",
       " 221: '▁bald',\n",
       " 222: '▁bar',\n",
       " 223: '▁be',\n",
       " 224: '▁beat',\n",
       " 225: '▁bed',\n",
       " 226: '▁beer',\n",
       " 227: '▁beg',\n",
       " 228: '▁bet',\n",
       " 229: '▁better',\n",
       " 230: '▁big',\n",
       " 231: '▁birds',\n",
       " 232: '▁bit',\n",
       " 233: '▁bl',\n",
       " 234: '▁blind',\n",
       " 235: '▁blue',\n",
       " 236: '▁bog',\n",
       " 237: '▁both',\n",
       " 238: '▁bott',\n",
       " 239: '▁bought',\n",
       " 240: '▁box',\n",
       " 241: '▁boy',\n",
       " 242: '▁bre',\n",
       " 243: '▁break',\n",
       " 244: '▁broke',\n",
       " 245: '▁bu',\n",
       " 246: '▁built',\n",
       " 247: '▁bul',\n",
       " 248: '▁buried',\n",
       " 249: '▁burned',\n",
       " 250: '▁bus',\n",
       " 251: '▁buy',\n",
       " 252: '▁c',\n",
       " 253: '▁ca',\n",
       " 254: '▁cal',\n",
       " 255: '▁call',\n",
       " 256: '▁calls',\n",
       " 257: '▁came',\n",
       " 258: '▁can',\n",
       " 259: '▁cant',\n",
       " 260: '▁care',\n",
       " 261: '▁cars',\n",
       " 262: '▁cash',\n",
       " 263: '▁catch',\n",
       " 264: '▁caught',\n",
       " 265: '▁cd',\n",
       " 266: '▁certain',\n",
       " 267: '▁ch',\n",
       " 268: '▁change',\n",
       " 269: '▁che',\n",
       " 270: '▁check',\n",
       " 271: '▁choose',\n",
       " 272: '▁class',\n",
       " 273: '▁clean',\n",
       " 274: '▁clear',\n",
       " 275: '▁coin',\n",
       " 276: '▁cold',\n",
       " 277: '▁come',\n",
       " 278: '▁coming',\n",
       " 279: '▁comment',\n",
       " 280: '▁conf',\n",
       " 281: '▁content',\n",
       " 282: '▁cook',\n",
       " 283: '▁cool',\n",
       " 284: '▁cop',\n",
       " 285: '▁could',\n",
       " 286: '▁count',\n",
       " 287: '▁course',\n",
       " 288: '▁cover',\n",
       " 289: '▁cr',\n",
       " 290: '▁cra',\n",
       " 291: '▁creative',\n",
       " 292: '▁cry',\n",
       " 293: '▁cur',\n",
       " 294: '▁cut',\n",
       " 295: '▁d',\n",
       " 296: '▁dance',\n",
       " 297: '▁dark',\n",
       " 298: '▁day',\n",
       " 299: '▁de',\n",
       " 300: '▁dead',\n",
       " 301: '▁deal',\n",
       " 302: '▁dec',\n",
       " 303: '▁deep',\n",
       " 304: '▁did',\n",
       " 305: '▁didn',\n",
       " 306: '▁die',\n",
       " 307: '▁died',\n",
       " 308: '▁dis',\n",
       " 309: '▁disc',\n",
       " 310: '▁dj',\n",
       " 311: '▁do',\n",
       " 312: '▁dog',\n",
       " 313: '▁dogs',\n",
       " 314: '▁don',\n",
       " 315: '▁done',\n",
       " 316: '▁doubt',\n",
       " 317: '▁down',\n",
       " 318: '▁dr',\n",
       " 319: '▁drive',\n",
       " 320: '▁drop',\n",
       " 321: '▁duty',\n",
       " 322: '▁e',\n",
       " 323: '▁early',\n",
       " 324: '▁eat',\n",
       " 325: '▁eggs',\n",
       " 326: '▁eight',\n",
       " 327: '▁else',\n",
       " 328: '▁en',\n",
       " 329: '▁even',\n",
       " 330: '▁exc',\n",
       " 331: '▁exerc',\n",
       " 332: '▁eyes',\n",
       " 333: '▁f',\n",
       " 334: '▁fail',\n",
       " 335: '▁failed',\n",
       " 336: '▁fair',\n",
       " 337: '▁famous',\n",
       " 338: '▁fant',\n",
       " 339: '▁far',\n",
       " 340: '▁fast',\n",
       " 341: '▁faster',\n",
       " 342: '▁fat',\n",
       " 343: '▁fear',\n",
       " 344: '▁feel',\n",
       " 345: '▁fell',\n",
       " 346: '▁felt',\n",
       " 347: '▁fill',\n",
       " 348: '▁fin',\n",
       " 349: '▁find',\n",
       " 350: '▁fine',\n",
       " 351: '▁finnish',\n",
       " 352: '▁fire',\n",
       " 353: '▁fired',\n",
       " 354: '▁first',\n",
       " 355: '▁fish',\n",
       " 356: '▁fit',\n",
       " 357: '▁fixed',\n",
       " 358: '▁fl',\n",
       " 359: '▁fly',\n",
       " 360: '▁follow',\n",
       " 361: '▁food',\n",
       " 362: '▁for',\n",
       " 363: '▁forg',\n",
       " 364: '▁found',\n",
       " 365: '▁fre',\n",
       " 366: '▁free',\n",
       " 367: '▁french',\n",
       " 368: '▁friendly',\n",
       " 369: '▁fruit',\n",
       " 370: '▁full',\n",
       " 371: '▁fun',\n",
       " 372: '▁g',\n",
       " 373: '▁gas',\n",
       " 374: '▁gave',\n",
       " 375: '▁get',\n",
       " 376: '▁give',\n",
       " 377: '▁gl',\n",
       " 378: '▁go',\n",
       " 379: '▁going',\n",
       " 380: '▁golf',\n",
       " 381: '▁good',\n",
       " 382: '▁got',\n",
       " 383: '▁gra',\n",
       " 384: '▁gre',\n",
       " 385: '▁green',\n",
       " 386: '▁grew',\n",
       " 387: '▁gu',\n",
       " 388: '▁h',\n",
       " 389: '▁had',\n",
       " 390: '▁hands',\n",
       " 391: '▁hang',\n",
       " 392: '▁hard',\n",
       " 393: '▁has',\n",
       " 394: '▁have',\n",
       " 395: '▁he',\n",
       " 396: '▁hel',\n",
       " 397: '▁help',\n",
       " 398: '▁helped',\n",
       " 399: '▁helps',\n",
       " 400: '▁her',\n",
       " 401: '▁here',\n",
       " 402: '▁hero',\n",
       " 403: '▁him',\n",
       " 404: '▁hired',\n",
       " 405: '▁his',\n",
       " 406: '▁hit',\n",
       " 407: '▁hold',\n",
       " 408: '▁home',\n",
       " 409: '▁hon',\n",
       " 410: '▁hop',\n",
       " 411: '▁hope',\n",
       " 412: '▁hot',\n",
       " 413: '▁how',\n",
       " 414: '▁hug',\n",
       " 415: '▁hum',\n",
       " 416: '▁human',\n",
       " 417: '▁hun',\n",
       " 418: '▁hung',\n",
       " 419: '▁hur',\n",
       " 420: '▁i',\n",
       " 421: '▁ice',\n",
       " 422: '▁id',\n",
       " 423: '▁ign',\n",
       " 424: '▁ill',\n",
       " 425: '▁im',\n",
       " 426: '▁imm',\n",
       " 427: '▁in',\n",
       " 428: '▁inside',\n",
       " 429: '▁is',\n",
       " 430: '▁it',\n",
       " 431: '▁italian',\n",
       " 432: '▁its',\n",
       " 433: '▁j',\n",
       " 434: '▁jazz',\n",
       " 435: '▁jer',\n",
       " 436: '▁job',\n",
       " 437: '▁join',\n",
       " 438: '▁jum',\n",
       " 439: '▁jump',\n",
       " 440: '▁just',\n",
       " 441: '▁keep',\n",
       " 442: '▁kid',\n",
       " 443: '▁kids',\n",
       " 444: '▁kind',\n",
       " 445: '▁kiss',\n",
       " 446: '▁kn',\n",
       " 447: '▁knew',\n",
       " 448: '▁know',\n",
       " 449: '▁korean',\n",
       " 450: '▁l',\n",
       " 451: '▁la',\n",
       " 452: '▁late',\n",
       " 453: '▁leave',\n",
       " 454: '▁left',\n",
       " 455: '▁let',\n",
       " 456: '▁li',\n",
       " 457: '▁lie',\n",
       " 458: '▁life',\n",
       " 459: '▁light',\n",
       " 460: '▁lik',\n",
       " 461: '▁like',\n",
       " 462: '▁listen',\n",
       " 463: '▁live',\n",
       " 464: '▁lo',\n",
       " 465: '▁lon',\n",
       " 466: '▁long',\n",
       " 467: '▁look',\n",
       " 468: '▁looked',\n",
       " 469: '▁losing',\n",
       " 470: '▁lost',\n",
       " 471: '▁lov',\n",
       " 472: '▁love',\n",
       " 473: '▁loyal',\n",
       " 474: '▁m',\n",
       " 475: '▁mad',\n",
       " 476: '▁made',\n",
       " 477: '▁man',\n",
       " 478: '▁manage',\n",
       " 479: '▁marry',\n",
       " 480: '▁mary',\n",
       " 481: '▁math',\n",
       " 482: '▁matters',\n",
       " 483: '▁may',\n",
       " 484: '▁me',\n",
       " 485: '▁mean',\n",
       " 486: '▁men',\n",
       " 487: '▁merc',\n",
       " 488: '▁mess',\n",
       " 489: '▁met',\n",
       " 490: '▁milk',\n",
       " 491: '▁mind',\n",
       " 492: '▁mine',\n",
       " 493: '▁mon',\n",
       " 494: '▁more',\n",
       " 495: '▁move',\n",
       " 496: '▁moved',\n",
       " 497: '▁moving',\n",
       " 498: '▁must',\n",
       " 499: '▁my',\n",
       " 500: '▁n',\n",
       " 501: '▁na',\n",
       " 502: '▁nap',\n",
       " 503: '▁need',\n",
       " 504: '▁needs',\n",
       " 505: '▁never',\n",
       " 506: '▁new',\n",
       " 507: '▁night',\n",
       " 508: '▁no',\n",
       " 509: '▁normal',\n",
       " 510: '▁not',\n",
       " 511: '▁now',\n",
       " 512: '▁ob',\n",
       " 513: '▁od',\n",
       " 514: '▁of',\n",
       " 515: '▁off',\n",
       " 516: '▁often',\n",
       " 517: '▁oh',\n",
       " 518: '▁ok',\n",
       " 519: '▁old',\n",
       " 520: '▁on',\n",
       " 521: '▁once',\n",
       " 522: '▁one',\n",
       " 523: '▁op',\n",
       " 524: '▁open',\n",
       " 525: '▁out',\n",
       " 526: '▁over',\n",
       " 527: '▁p',\n",
       " 528: '▁pack',\n",
       " 529: '▁pan',\n",
       " 530: '▁pass',\n",
       " 531: '▁pay',\n",
       " 532: '▁perfect',\n",
       " 533: '▁ph',\n",
       " 534: '▁pick',\n",
       " 535: '▁ple',\n",
       " 536: '▁po',\n",
       " 537: '▁poor',\n",
       " 538: '▁pray',\n",
       " 539: '▁prepared',\n",
       " 540: '▁problem',\n",
       " 541: '▁prom',\n",
       " 542: '▁pun',\n",
       " 543: '▁qu',\n",
       " 544: '▁quick',\n",
       " 545: '▁quiet',\n",
       " 546: '▁ran',\n",
       " 547: '▁read',\n",
       " 548: '▁ready',\n",
       " 549: '▁real',\n",
       " 550: '▁really',\n",
       " 551: '▁recovered',\n",
       " 552: '▁ref',\n",
       " 553: '▁rel',\n",
       " 554: '▁remember',\n",
       " 555: '▁resigned',\n",
       " 556: '▁rest',\n",
       " 557: '▁rice',\n",
       " 558: '▁rich',\n",
       " 559: '▁right',\n",
       " 560: '▁rock',\n",
       " 561: '▁ru',\n",
       " 562: '▁run',\n",
       " 563: '▁runs',\n",
       " 564: '▁rush',\n",
       " 565: '▁ruth',\n",
       " 566: '▁s',\n",
       " 567: '▁sa',\n",
       " 568: '▁sad',\n",
       " 569: '▁safe',\n",
       " 570: '▁said',\n",
       " 571: '▁sand',\n",
       " 572: '▁sat',\n",
       " 573: '▁saved',\n",
       " 574: '▁saw',\n",
       " 575: '▁say',\n",
       " 576: '▁sc',\n",
       " 577: '▁scre',\n",
       " 578: '▁se',\n",
       " 579: '▁seat',\n",
       " 580: '▁sec',\n",
       " 581: '▁see',\n",
       " 582: '▁sell',\n",
       " 583: '▁sens',\n",
       " 584: '▁serious',\n",
       " 585: '▁set',\n",
       " 586: '▁sh',\n",
       " 587: '▁shadow',\n",
       " 588: '▁sharp',\n",
       " 589: '▁she',\n",
       " 590: '▁shoot',\n",
       " 591: '▁shot',\n",
       " 592: '▁should',\n",
       " 593: '▁show',\n",
       " 594: '▁shut',\n",
       " 595: '▁sick',\n",
       " 596: '▁sig',\n",
       " 597: '▁sign',\n",
       " 598: '▁sing',\n",
       " 599: '▁single',\n",
       " 600: '▁sit',\n",
       " 601: '▁sk',\n",
       " 602: '▁ski',\n",
       " 603: '▁sl',\n",
       " 604: '▁sleep',\n",
       " 605: '▁slow',\n",
       " 606: '▁sm',\n",
       " 607: '▁smart',\n",
       " 608: '▁sn',\n",
       " 609: '▁snow',\n",
       " 610: '▁so',\n",
       " 611: '▁some',\n",
       " 612: '▁soon',\n",
       " 613: '▁sor',\n",
       " 614: '▁sou',\n",
       " 615: '▁speak',\n",
       " 616: '▁spoke',\n",
       " 617: '▁squ',\n",
       " 618: '▁st',\n",
       " 619: '▁stand',\n",
       " 620: '▁start',\n",
       " 621: '▁stay',\n",
       " 622: '▁stayed',\n",
       " 623: '▁step',\n",
       " 624: '▁still',\n",
       " 625: '▁stood',\n",
       " 626: '▁stop',\n",
       " 627: '▁strict',\n",
       " 628: '▁strong',\n",
       " 629: '▁study',\n",
       " 630: '▁sun',\n",
       " 631: '▁sure',\n",
       " 632: '▁surrender',\n",
       " 633: '▁survived',\n",
       " 634: '▁sw',\n",
       " 635: '▁sweet',\n",
       " 636: '▁swim',\n",
       " 637: '▁swiss',\n",
       " 638: '▁t',\n",
       " 639: '▁take',\n",
       " 640: '▁talk',\n",
       " 641: '▁tall',\n",
       " 642: '▁taxes',\n",
       " 643: '▁tea',\n",
       " 644: '▁tell',\n",
       " 645: '▁ter',\n",
       " 646: '▁th',\n",
       " 647: '▁than',\n",
       " 648: '▁thanks',\n",
       " 649: '▁that',\n",
       " 650: '▁the',\n",
       " 651: '▁them',\n",
       " 652: '▁there',\n",
       " 653: '▁they',\n",
       " 654: '▁thin',\n",
       " 655: '▁thirty',\n",
       " 656: '▁this',\n",
       " 657: '▁tim',\n",
       " 658: '▁time',\n",
       " 659: '▁to',\n",
       " 660: '▁tom',\n",
       " 661: '▁too',\n",
       " 662: '▁tried',\n",
       " 663: '▁tries',\n",
       " 664: '▁trip',\n",
       " 665: '▁true',\n",
       " 666: '▁trust',\n",
       " 667: '▁try',\n",
       " 668: '▁turn',\n",
       " 669: '▁two',\n",
       " 670: '▁ug',\n",
       " 671: '▁up',\n",
       " 672: '▁us',\n",
       " 673: '▁use',\n",
       " 674: '▁voted',\n",
       " 675: '▁w',\n",
       " 676: '▁wa',\n",
       " 677: '▁wait',\n",
       " 678: '▁wake',\n",
       " 679: '▁wal',\n",
       " 680: '▁walk',\n",
       " 681: '▁want',\n",
       " 682: '▁war',\n",
       " 683: '▁warm',\n",
       " 684: '▁was',\n",
       " 685: '▁watch',\n",
       " 686: '▁way',\n",
       " 687: '▁we',\n",
       " 688: '▁weak',\n",
       " 689: '▁well',\n",
       " 690: '▁went',\n",
       " 691: '▁were',\n",
       " 692: '▁wet',\n",
       " 693: '▁wh',\n",
       " 694: '▁what',\n",
       " 695: '▁where',\n",
       " 696: '▁who',\n",
       " 697: '▁why',\n",
       " 698: '▁will',\n",
       " 699: '▁win',\n",
       " 700: '▁wine',\n",
       " 701: '▁won',\n",
       " 702: '▁wonder',\n",
       " 703: '▁wor',\n",
       " 704: '▁work',\n",
       " 705: '▁worked',\n",
       " 706: '▁works',\n",
       " 707: '▁write',\n",
       " 708: '▁wrong',\n",
       " 709: '▁wrote',\n",
       " 710: '▁y',\n",
       " 711: '▁you',\n",
       " 712: '▁young',\n",
       " 713: '▁your'}"
      ]
     },
     "execution_count": 139,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_input_char_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 732,
     "status": "ok",
     "timestamp": 1562230755320,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "8XPkKsbXej9F",
    "outputId": "c59450a5-9088-4819-c002-abd3f1d98b8c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eng</th>\n",
       "      <th>fre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>go home now</td>\n",
       "      <td>$_ va à la maison maintenant _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1434</th>\n",
       "      <td>who saw me</td>\n",
       "      <td>$_ qui ma vu _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>hold on</td>\n",
       "      <td>$_ ne quittez pas _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>i like him</td>\n",
       "      <td>$_ je lapprécie _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>join us</td>\n",
       "      <td>$_ joignezvous à nous _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>im sorry</td>\n",
       "      <td>$_ je suis désolé _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1227</th>\n",
       "      <td>let him go</td>\n",
       "      <td>$_ laissezle sen aller _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>how are you</td>\n",
       "      <td>$_ comment allonsnous _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>838</th>\n",
       "      <td>ask anyone</td>\n",
       "      <td>$_ demandez à nimporte qui _#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>i went too</td>\n",
       "      <td>$_ jy suis également allé _#</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              eng                              fre\n",
       "1621  go home now  $_ va à la maison maintenant _#\n",
       "1434   who saw me                  $_ qui ma vu _#\n",
       "125       hold on             $_ ne quittez pas _#\n",
       "1016   i like him               $_ je lapprécie _#\n",
       "143       join us         $_ joignezvous à nous _#\n",
       "611      im sorry             $_ je suis désolé _#\n",
       "1227   let him go        $_ laissezle sen aller _#\n",
       "1700  how are you         $_ comment allonsnous _#\n",
       "838    ask anyone    $_ demandez à nimporte qui _#\n",
       "1951   i went too     $_ jy suis également allé _#"
      ]
     },
     "execution_count": 140,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines = shuffle(lines)\n",
    "lines.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YPh4_4cQej9L"
   },
   "outputs": [],
   "source": [
    "# Train - Test Split\n",
    "X, y = lines.eng,lines.fre\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1271,
     "status": "ok",
     "timestamp": 1562146596712,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "V5cMOBKTK-jZ",
    "outputId": "aab1ead1-2745-4e25-dda4-6761e9bdb723"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1800"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1305,
     "status": "ok",
     "timestamp": 1562146563937,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "od-0bCNyL_xc",
    "outputId": "07a1660c-7092-44d4-eae2-96943166a0c5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 101,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M_2VX4gYvobf"
   },
   "outputs": [],
   "source": [
    "X_train=pd.Series(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yARtGk4Hej9P"
   },
   "outputs": [],
   "source": [
    "y_train=pd.Series(y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "thXRatq7ej9Q"
   },
   "outputs": [],
   "source": [
    "y_test=pd.Series(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "OAyc5hOMej9T",
    "outputId": "85a238e0-eb8d-4e13-cf62-ea12b59b5061"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lO1XCA26ej9V"
   },
   "source": [
    "#### Save the train and test dataframes for reproducing the results later, as they are shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wdD2CFwMej9W"
   },
   "outputs": [],
   "source": [
    "X_train.to_pickle('X_train.pkl')\n",
    "X_test.to_pickle('X_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eQeZKzUafy1U"
   },
   "outputs": [],
   "source": [
    "train_samples = len(X_train)\n",
    "val_samples = len(X_test)\n",
    "batch_size = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gXSnRlPwjHYC"
   },
   "outputs": [],
   "source": [
    "def generate_batch(X = X_train, y = y_train, batch_size =128 ):\n",
    "    ''' Generate a batch of data '''\n",
    "    while True:\n",
    "        for j in range(0, len(X), batch_size):\n",
    "            encoder_input_data = np.zeros((batch_size, max_length_src),dtype='float32')\n",
    "            decoder_input_data = np.zeros((batch_size, max_length_tar),dtype='float32')\n",
    "            decoder_target_data = np.zeros((batch_size, max_length_tar, num_decoder_tokens),dtype='float32')\n",
    "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
    "                subword_eng=bpemb_en.encode(input_text)\n",
    "                for t, word in enumerate(subword_eng):\n",
    "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
    "                for t, word in enumerate(target_text.split()):\n",
    "                    if t<len(target_text.split())-1:\n",
    "                            ch = [ch for ch in word]\n",
    "                            for ch in ch:\n",
    "                                decoder_input_data[i, t] = char_to_ix[ch] # decoder input seq\n",
    "                    if t>0:\n",
    "                        # decoder target sequence (one hot encoded)\n",
    "                        # does not include the START_ token\n",
    "                        # Offset by one timestep\n",
    "                            ch = [ch for ch in word]\n",
    "                            for ch in ch:\n",
    "                                decoder_target_data[i, t - 1, char_to_ix[ch]] = 1.\n",
    "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JliG5hNAjHgv"
   },
   "source": [
    "# Encoder - Decoder Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fWBe--PFej9k"
   },
   "outputs": [],
   "source": [
    "latent_dim = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cd1iYwUpej9m"
   },
   "outputs": [],
   "source": [
    "# Encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hRHM5Myej9o"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9xS-nxpMej9r"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15397,
     "status": "ok",
     "timestamp": 1562230857383,
     "user": {
      "displayName": "Jaswant Kumar",
      "photoUrl": "https://lh6.googleusercontent.com/-q9pbC5zjOIY/AAAAAAAAAAI/AAAAAAAAAAo/1OYGdg39U84/s64/photo.jpg",
      "userId": "17132398173832355271"
     },
     "user_tz": -330
    },
    "id": "EY_F_xWZej9u",
    "outputId": "df5a6107-ed17-4642-8c2b-35a92fb2c48a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14/14 [==============================] - 8s 539ms/step - loss: 12.9540 - acc: 0.2206 - val_loss: 12.0282 - val_acc: 0.2444\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 2s 128ms/step - loss: 11.3923 - acc: 0.2319 - val_loss: 10.6712 - val_acc: 0.2125\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 2s 129ms/step - loss: 10.7579 - acc: 0.2182 - val_loss: 10.5912 - val_acc: 0.2136\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 2s 129ms/step - loss: 10.4279 - acc: 0.2059 - val_loss: 10.1696 - val_acc: 0.1905\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 2s 130ms/step - loss: 10.2920 - acc: 0.2061 - val_loss: 10.2134 - val_acc: 0.2012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcb3936ec50>"
      ]
     },
     "execution_count": 153,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
    "                    steps_per_epoch = train_samples//batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
    "                    validation_steps = val_samples//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v3qtx3Gjej9x"
   },
   "source": [
    "### Always remember to save the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zl7OT7V1ej9y"
   },
   "outputs": [],
   "source": [
    "model.save_weights('nmt_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CR_TrKwTej90"
   },
   "source": [
    "### Load the weights, if you close the application"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "subword_bpe_characterLevelEngMarNMT.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
